---
title: "Capstone Project"
author: "Kathy Smith"
format: 
  html:
    self-contained: true
execute:
  echo: true
  warning: false
  message: false
  error: true
editor: source
---

# The main measures to be predicted: DX, ADAS13, Ventricles
# Cognitive tests: CDRSB, ADAS11, MMSE, RAVLT_immediate
# MRI measures: Hippocampus, WholeBrain, Entorhinal, MidTemp
# PET measures: FDG, AV45
# CSF measures: ABETA_UPENNBIOMK9_04_19_17  (amyloid-beta level in CSF), TAU_UPENNBIOMK9_04_19_17 (tau level), PTAU_UPENNBIOMK9_04_19_17 (phosphorylated tau level)
# Risk factors: APOE4, AGE

# Main cognitive tests (excluding subtypes): - neuropsychological tests administered by a clinical expert 1. CDR Sum of Boxes 2. ADAS11 3. ADAS13 4. MMSE 5. RAVLT 6. Moca 7. Ecog
# MRI ROIs (Freesurfer) - measures of brain structural integrity 1. volumes 2. cortical thicknesses 3. surface areas
# FDG PET ROI averages - measure cell metabolism, where cells affected by AD show reduced metabolism
# AV45 PET ROI averages - measures amyloid-beta load in the brain, where amyloid-beta is a protein that mis-folds (i.e. its 3D structure is not properly constructed), which then leads to AD
# AV1451 PET ROI averages - measures tau load in the brain, where tau is another protein which, when abnormal, damages neurons and thus leads to AD
# DTI ROI measures - measures microstructural parameters related to cells and axons (cell radial diffusivity, axonal diffusivity, etc ... ) 1. Mean diffusivity 2. Axial diffusivity 3. Radial diffusivity
# CSF biomarkers - amyloid and tau levels in the cerebrospinal fluid (CSF), as opposed to the cerebral cortex
# Others: 1. APOE status - a gene that is a risk factor for developing AD 2. Demographic information: age, gender, education, etc ... 3. Diagnosis: either cognitively cormal (CN), mild cognitive impairment (MCI) or Alzheimer's disease (AD).
#   

```{r}

# Import the necessary libraries
library(tidyverse)
library(haven)
library(dplyr)
library(fastDummies)
library(nnet)
library(caret)
library(classpackage)
library(pROC)
library(ggplot2)
library(reshape2)
library(caret)

# Read the ADNI data file
Data_D1D2 <- read_csv("~/Capstone/TADPOLE_D1_D2_2.csv")

# Rename columns
Data_D1D2 <- Data_D1D2 %>% rename(
  ABETA = ABETA_UPENNBIOMK9_04_19_17,
  TAU = TAU_UPENNBIOMK9_04_19_17,
  PTAU = PTAU_UPENNBIOMK9_04_19_17)

# Convert PTAU from a char to numeric
Data_D1D2 <- Data_D1D2 %>%
  mutate(
    PTAU = as.numeric(PTAU))

# Scale continuous Predictors
Data_D1D2 <- Data_D1D2 %>%
  mutate(
    ABETA = scale(ABETA),
    PTAU = scale(PTAU),
    TAU = scale(TAU),
    Hippocampus = scale(Hippocampus), 
    WholeBrain = scale(WholeBrain), 
    Entorhinal = scale(Entorhinal), 
    Ventricles = scale(Ventricles), 
    Fusiform = scale(Fusiform),
    RAVLT_immediate = scale(RAVLT_immediate))

# Extract Training Data
# Subjects at baseline that were diagnosed with MCI or AD
Data_D1D2 <- Data_D1D2 %>%
  filter(VISCODE == 'bl',
         DX == 'MCI'| DX == 'Dementia') %>%
   select(RID, VISCODE, DX_bl, DX, DXCHANGE, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, ABETA, TAU, PTAU, Hippocampus, WholeBrain, Entorhinal, Ventricles, Fusiform) %>%
na.omit()

view(Data_D1D2)

# Create a partition for training data
set.seed(123)
train_index <- createDataPartition(Data_D1D2$DX, p = 0.7, list = FALSE)  # 70% for training

# Split the dataset into training and test sets
Training_Data_D1D2 <- Data_D1D2[train_index, ]
Test_Data_D1D2 <- Data_D1D2[-train_index, ]

# Check the dimensions of the training and test sets
cat("Training set dimensions:", dim(Training_Data_D1D2), "\n")
cat("Test set dimensions:", dim(Test_Data_D1D2), "\n")

#-----------BALANCE DATA----------------

# Function to perform undersampling
undersample_data <- function(data, target_class) {
  # Count the number of instances in the target (minority) class
  minority_count <- sum(data$DX == target_class)
  
  # Select instances from the minority class
  minority_data <- data[data$DX == target_class, ]
  
  # Select instances from the majority class, randomly
  majority_data <- data[data$DX != target_class, ]
  
  # Randomly sample from the majority class to match the minority count
  majority_data_sampled <- majority_data[sample(nrow(majority_data), minority_count), ]
  
  # Combine the sampled majority class with the minority class
  balanced_data <- rbind(minority_data, majority_data_sampled)
  
  return(balanced_data)
}

# Perform undersampling to balance the training and test datasets
Training_Data_D1D2 <- undersample_data(Training_Data_D1D2, "Dementia")
Test_Data_D1D2 <- undersample_data(Test_Data_D1D2, "Dementia")

# Check the new distribution of the classes
Training_Data_D1D2 %>%
  count(DX)

Test_Data_D1D2 %>%
  count(DX)


#-----------BALANCE DATA END----------------

#-------OPTION #2 FOR SETTING TRAINING AND TEST DATA-------------

# # Check the distribution of the diagnosis in the training data
# table(Training_Data_D1D2$DX)
# 
# # Separate data into two categories
# class_0 <- Training_Data_D1D2[Training_Data_D1D2$DX == 'MCI', ]  
# class_1 <- Training_Data_D1D2[Training_Data_D1D2$DX == 'Dementia', ] 
# 
# # Determine the number of samples to select from each class
# n_class_1 <- nrow(class_1)  # Number of samples in the MCI class
# balanced_class_0 <- class_0 %>% sample_n(n_class_1)  # Randomly sample from the Demential (AD) Class
# 
# # Combine the sampled majority class with the minority class
# Training_Data_D1D2 <- rbind(balanced_class_0, class_1)
# Training_Data_D1D2 %>%
#   count(DX)
# 
# # Extract Test Data at 24 months
# # Include subjects that transitioned from MCI to AD (DXCHANGE = 5) at 24 months and those that remained stable (DXCHANGE = 2)
# Test_Data_D1D2 <- Data_D1D2 %>% 
#   filter(VISCODE == 'm24',
#          DXCHANGE == 5 | DXCHANGE == 2) %>%
#    select(RID, VISCODE, DX_bl, DX, DXCHANGE, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, ABETA, TAU, PTAU, Hippocampus, WholeBrain, Entorhinal, Ventricles, Fusiform) %>%
# na.omit()
# 
# # Check the distribution of the diagnosis in the test data
# table(Test_Data_D1D2$DXCHANGE)
# 
# # Separate data into two categories
# class_0 <- Test_Data_D1D2[Test_Data_D1D2$DXCHANGE == 2, ]  
# class_1 <- Test_Data_D1D2[Test_Data_D1D2$DXCHANGE == 5, ] 
# 
# # Determine the number of samples to select from each class
# n_class_1 <- nrow(class_1)  # Number of samples in the MCI to AD Class
# balanced_class_0 <- class_0 %>% sample_n(n_class_1)  # Randomly sample from the MCI to MCI Class
# 
# # Combine the sampled majority class with the minority class
# Test_Data_D1D2 <- rbind(balanced_class_0, class_1)
# Test_Data_D1D2 %>%
#   count(DXCHANGE)
# 
# View(Training_Data_D1D2)
# View(Test_Data_D1D2)
#   
#-------OPTION #2 FOR SETTING TRAINING AND TEST DATA-------------



# Create a binary indicator variable for MCI and AD diagnosis for both training and test data
Analysis_Training_Data_D1D2 <- Training_Data_D1D2 %>%
   mutate(diagnosisAD = if_else(DX == "Dementia", 1, 0)) %>%
dummy_cols(select_columns = c("diagnosisAD"))

Analysis_Test_Data_D1D2 <- Test_Data_D1D2 %>%
   mutate(diagnosisAD = if_else(DX == "Dementia", 1, 0)) %>%
dummy_cols(select_columns = c("diagnosisAD"))

# Write training and test data files
write.csv(Analysis_Training_Data_D1D2, "~/Capstone/training_data.csv", row.names = TRUE)
write.csv(Analysis_Test_Data_D1D2, "~/Capstone/test_data.csv", row.names = TRUE)

```

*PERFORM REGRESSION ANALYSIS*

- CSF BIOMARKERS, ABETA + TAU + PTAU


```{r}

# Fit logistic regression model
m1 <- glm(diagnosisAD ~ ABETA + TAU + PTAU,
                 data = Analysis_Training_Data_D1D2, family = "binomial")
summary(m1)

# Check for outliers
car::outlierTest(m1)

# Check the significance of the model
reduced <- glm(diagnosisAD ~ 1, data = Analysis_Training_Data_D1D2, family = "binomial"(link="logit")) 
anova(reduced, m1, test = "LRT")
car::Anova(m1, type = 3)
round(confint(m1), 4)

# Generate predicted probabilities using the test data set
Analysis_Test_Data_D1D2$Predicted_Probability_m1 <- predict(m1, newdata = Analysis_Test_Data_D1D2, type = "response")
view(Analysis_Test_Data_D1D2)

# Create ROC curve
roc_curve <- roc(Analysis_Test_Data_D1D2$diagnosisAD, Analysis_Test_Data_D1D2$Predicted_Probability_m1)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve - CSF Biomarkers", col = "blue")

# Print AUC
print(paste("AUC - CSF Biomarkers:", auc(roc_curve)))

# Convert predicted probabilities to predicted classes
predicted_classes <- ifelse(Analysis_Test_Data_D1D2$Predicted_Probability_m1 > .2, 1, 0)

# Create a confusion matrix
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(Analysis_Test_Data_D1D2$diagnosisAD))
print(confusion_matrix)

# Plot the confusion matrix
heatmap_data <- as.data.frame(confusion_matrix$table)
colnames(heatmap_data) <- c("Predicted", "Actual", "Freq")
ggplot(heatmap_data, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(title = "Confusion Matrix Heatmap")


#----------------SVM MODEL----------------------

Analysis_Training_Data_D1D2 %>%
  count(diagnosisAD)

# Train the SVM model
library(e1071)
svm_model <- svm(diagnosisAD ~ ABETA + TAU + PTAU, data = Analysis_Training_Data_D1D2,
                 kernel = "polynomial", degree = 6, 
                 cost = 1)  # Adjust weights as needed
# Print model summary
summary(svm_model)

# Make predictions on the test set
predictions <- predict(svm_model, Analysis_Test_Data_D1D2)

# Print the predictions
print(predictions)

# Evaluate the model using a confusion matrix
conf_matrix <- confusionMatrix(as.factor(predictions), as.factor(Analysis_Test_Data_D1D2$diagnosisAD))
print(conf_matrix)

# Calculate accuracy
accuracy <- sum(predictions == Analysis_Test_Data_D1D2$diagnosisAD) / length(predictions)
print(paste("Accuracy:", round(accuracy, 3)))

# Plot the confusion matrix
conf_matrix_table <- as.data.frame(conf_matrix$table)

# Reshape the data for ggplot2
conf_matrix_table <- melt(conf_matrix_table)

# Create the plot
ggplot(data = conf_matrix_table, aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = value), color = "white") +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = value), color = "black") +
  theme_minimal() +
  labs(title = "Confusion Matrix", x = "Actual", y = "Predicted")

# ---------------END SVM------------------------


#----------------RANDOM FOREST-------------------
library(randomForest)

# Train the Random Forest model
rf_model <- randomForest(diagnosisAD ~ ABETA + TAU + PTAU, data = Analysis_Training_Data_D1D2, ntree = 100)
print(rf_model)

# Make predictions on the test set
predictions <- predict(rf_model, newdata = Analysis_Test_Data_D1D2)

# Create a confusion matrix
confusion_matrix <- table(Analysis_Test_Data_D1D2$diagnosisAD, predictions)
print(confusion_matrix)

# Calculate accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")

# Plot variable importance
importance(rf_model)
varImpPlot(rf_model)

# Plot the confusion matrix
conf_matrix_table <- as.data.frame(confusion_matrix$table)

# Reshape the data for ggplot2
conf_matrix_table <- melt(conf_matrix_table)

# Create the plot
ggplot(data = conf_matrix_table, aes(x = Reference, y = Prediction)) +
  geom_tile(aes(fill = value), color = "white") +
  scale_fill_gradient(low = "white", high = "blue") +
  geom_text(aes(label = value), color = "black") +
  theme_minimal() +
  labs(title = "Confusion Matrix", x = "Actual", y = "Predicted")




```

- MRI BIOMARKERS, Hippocampus,,WholeBraiN, EntorhinaL, Ventricles, Fusiform

```{r}

m2 <- glm(diagnosisAD ~ Hippocampus + WholeBrain + Entorhinal + Ventricles + Fusiform,
                 data = Analysis_Training_Data_D1D2, family = "binomial")
summary(m2)

# Check for outliers
car::outlierTest(m2)

# Check the significance of the model
reduced <- glm(diagnosisAD ~ 1, data = Analysis_Training_Data_D1D2, family = "binomial"(link="logit")) 
anova(reduced, m2, test = "LRT")
car::Anova(m2, type = 3)
round(confint(m2), 4)

# Generate predicted probabilities using the test data set
Analysis_Test_Data_D1D2$Predicted_Probability_m2 <- predict(m2, newdata = Analysis_Test_Data_D1D2, type = "response")

# Create ROC curve
roc_curve <- roc(Analysis_Test_Data_D1D2$diagnosisAD, Analysis_Test_Data_D1D2$Predicted_Probability_m2)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve - MRI Biomarkers", col = "red")

# Print AUC
print(paste("AUC - MRI Biomarkers:", auc(roc_curve)))

# Convert predicted probabilities to predicted classes
predicted_classes <- ifelse(Analysis_Test_Data_D1D2$Predicted_Probability_m2 > .3, 1, 0)

# Create a confusion matrix
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(Analysis_Test_Data_D1D2$diagnosisAD))

# Plot the confusion matrix
heatmap_data <- as.data.frame(confusion_matrix$table)
colnames(heatmap_data) <- c("Predicted", "Actual", "Freq")
ggplot(heatmap_data, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "red") +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(title = "Confusion Matrix Heatmap")

```

- COGNITIVE TESTS: RAVLT_immediate

```{r}
m3 <- glm(diagnosisAD ~ RAVLT_immediate,
                 data = Analysis_Training_Data_D1D2, family = "binomial")
summary(m3)

# Check for outliers
car::outlierTest(m3)

# Check the significance of the model
reduced <- glm(diagnosisAD ~ 1, data = Analysis_Training_Data_D1D2, family = "binomial"(link="logit")) 
anova(reduced, m3, test = "LRT")
car::Anova(m3, type = 3)
round(confint(m3), 4)

# Generate predicted probabilities using the test data set
Analysis_Test_Data_D1D2$Predicted_Probability_m3 <- predict(m3, newdata = Analysis_Test_Data_D1D2, type = "response")

# Create ROC curve
roc_curve <- roc(Analysis_Test_Data_D1D2$diagnosisAD, Analysis_Test_Data_D1D2$Predicted_Probability_m3)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve - Cognitive Tests", col = "green")

# Print AUC
print(paste("AUC - Cognitive Tests:", auc(roc_curve)))


# Convert predicted probabilities to predicted classes
predicted_classes <- ifelse(Analysis_Test_Data_D1D2$Predicted_Probability_m3 > .2, 1, 0)

# Create a confusion matrix
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(Analysis_Test_Data_D1D2$diagnosisAD))

# Plot the confusion matrix
heatmap_data <- as.data.frame(confusion_matrix$table)
colnames(heatmap_data) <- c("Predicted", "Actual", "Freq")
ggplot(heatmap_data, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "green") +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(title = "Confusion Matrix Heatmap")

```

- CSF AND COGNITIVE TESTS: ABETA and RAVLT_immediate

```{r}

m4 <- glm(diagnosisAD ~ ABETA + RAVLT_immediate,
                 data = Analysis_Training_Data_D1D2, family = "binomial")
summary(m4)

# Check for outliers
car::outlierTest(m4)

# Check the significance of the model
reduced <- glm(diagnosisAD ~ 1, data = Analysis_Training_Data_D1D2, family = "binomial"(link="logit")) 
anova(reduced, m4, test = "LRT")
car::Anova(m4, type = 3)
round(confint(m4), 4)

# Generate predicted probabilities using the test data set
Analysis_Test_Data_D1D2$Predicted_Probability_m4 <- predict(m4, newdata = Analysis_Test_Data_D1D2, type = "response")

# Create ROC curve
roc_curve <- roc(Analysis_Test_Data_D1D2$diagnosisAD, Analysis_Test_Data_D1D2$Predicted_Probability_m4)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve - Cognitive Tests _ CSF Biomarkers", col = "purple")

# Print AUC
print(paste("AUC - Cognitive Tests + CSF Biomarkers:", auc(roc_curve)))


# Convert predicted probabilities to predicted classes
predicted_classes <- ifelse(Analysis_Test_Data_D1D2$Predicted_Probability_m4 > .2, 1, 0)

# Create a confusion matrix
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(Analysis_Test_Data_D1D2$diagnosisAD))

# Plot the confusion matrix
heatmap_data <- as.data.frame(confusion_matrix$table)
colnames(heatmap_data) <- c("Predicted", "Actual", "Freq")
ggplot(heatmap_data, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "purple") +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(title = "Confusion Matrix Heatmap")

```
- MRI AND COGNITIVE TESTS: Hippocampus and RAVLT_immediate

```{r}

m5 <- glm(diagnosisAD ~ Hippocampus + RAVLT_immediate,
                 data = Analysis_Training_Data_D1D2, family = "binomial")
summary(m5)

# Check for outliers
car::outlierTest(m5)

# Check the significance of the model
reduced <- glm(diagnosisAD ~ 1, data = Analysis_Training_Data_D1D2, family = "binomial"(link="logit")) 
anova(reduced, m5, test = "LRT")
car::Anova(m5, type = 3)
round(confint(m5), 4)

# Generate predicted probabilities using the test data set
Analysis_Test_Data_D1D2$Predicted_Probability_m5 <- predict(m5, newdata = Analysis_Test_Data_D1D2, type = "response")

# Create ROC curve
roc_curve <- roc(Analysis_Test_Data_D1D2$diagnosisAD, Analysis_Test_Data_D1D2$Predicted_Probability_m5)

# Plot ROC curve
plot(roc_curve, main = "ROC Curve - Cognitive Tests _ CSF Biomarkers", col = "lightblue")

# Print AUC
print(paste("AUC - Cognitive Tests + CSF Biomarkers:", auc(roc_curve)))


# Convert predicted probabilities to predicted classes
predicted_classes <- ifelse(Analysis_Test_Data_D1D2$Predicted_Probability_m5 > .2, 1, 0)

# Create a confusion matrix
confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(Analysis_Test_Data_D1D2$diagnosisAD))

# Plot the confusion matrix
heatmap_data <- as.data.frame(confusion_matrix$table)
colnames(heatmap_data) <- c("Predicted", "Actual", "Freq")
ggplot(heatmap_data, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "lightblue") +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(title = "Confusion Matrix Heatmap")


```


























```{r}
# Import the necessary libraries
library(tidyverse)
library(haven)
library(dplyr)
library(fastDummies)
library(nnet)
library(caret)
library(classpackage)

Data_D1D2 <- read_csv("~/Capstone/TADPOLE_D1_D2_2.csv")

# Keep only baseline data that includes ABETA, TAU, and PTAU measures
Data_D1D2 <- Data_D1D2 %>% 
  filter(VISCODE == 'bl',
         ABETA_UPENNBIOMK9_04_19_17 > 0,
         TAU_UPENNBIOMK9_04_19_17 > 0,
         PTAU_UPENNBIOMK9_04_19_17 > 0) %>%
   select(RID, VISCODE, PTMARRY, EXAMDATE, DX_bl, DX, DXCHANGE, AGE, PTGENDER, PTETHCAT, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, FDG, AV45, ABETA_UPENNBIOMK9_04_19_17, TAU_UPENNBIOMK9_04_19_17, PTAU_UPENNBIOMK9_04_19_17, Hippocampus, WholeBrain, Entorhinal, MidTemp) %>%
na.omit()

# Create a dataframe
Data_D1D2 <- as.data.frame(Data_D1D2)

# Rename columns
Data_D1D2 <- Data_D1D2 %>% rename(
  ABETA = ABETA_UPENNBIOMK9_04_19_17,
  TAU = TAU_UPENNBIOMK9_04_19_17,
  PTAU = PTAU_UPENNBIOMK9_04_19_17)

str(Data_D1D2)

# Perform data cleanup and scale the parameters
Data_D1D2 <- Data_D1D2 %>%
  mutate(
    PTAU = as.numeric(PTAU))
 #   ABETA = ABETA/10,
  #  TAU = TAU/10,
   # Hippocampus = Hippocampus/100)

# Check the data
Data_D1D2 %>%
  select(RID, VISCODE, PTMARRY, EXAMDATE, DX_bl, DX, DXCHANGE, AGE, PTGENDER, PTETHCAT, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, FDG, AV45, ABETA, TAU, PTAU, Hippocampus, WholeBrain, Entorhinal, Ventricles) %>%
  head(n=300)

# Handle missing data for other measures
Data_D1D2 <- Data_D1D2
for(i in 1:ncol(Data_D1D2)) {
  if(is.numeric(Data_D1D2[[i]])) {
    Data_D1D2[[i]][is.na(Data_D1D2[[i]])] <- mean(Data_D1D2[[i]], na.rm = TRUE)
  }
}

write.csv(Data_D1D2, "~/Capstone/Subset_D1D1.csv", row.names = TRUE)

Data_D1D2$DX_bl <- as.factor(Data_D1D2$DX_bl)
Data_D1D2  %>%
  count(DX_bl)

# Create an indicator variable for educatiom status
Data_D1D2 <- Data_D1D2 %>%
  mutate(Diagnosis = case_when(DX_bl == 'AD' ~"5-AD",          
                                  DX_bl == 'LMCI' ~ "4-LMCI",  
                                  DX_bl == 'EMCI' ~ "3-EMCI",
                                  DX_bl == 'SMC' ~ "2-SMC",
                                  TRUE ~ "1-NC")) %>%           
dummy_cols(select_columns = c("Diagnosis"))  
Data_D1D2  %>%
  count(Diagnosis)

Data_D1D2 <- Data_D1D2 %>%
  mutate(Gender = case_when(PTGENDER == 'Female' ~"Female",
                                  TRUE ~ "Male")) %>%
dummy_cols(select_columns = c("Gender"))

# Set a seed for reproducibility
#set.seed(123)

# Specify the percentage of data for training (e.g., 80%)
trainIndex <- createDataPartition(Data_D1D2$DX_bl, p = 0.8, list = FALSE)

# Split data into training and testing sets
train_data <- Data_D1D2[trainIndex, ]
test_data <- Data_D1D2[-trainIndex, ]
view(train_data)
view(test_data)

# Write training and test data files
write.csv(train_data, "~/Capstone/training_data.csv", row.names = TRUE)
write.csv(test_data, "~/Capstone/test_data.csv", row.names = TRUE)

#  Construct the multinomial model
# Convert DX to a factor for multinomial classification

# 
# m1 <- MASS::polr(Diagnosis ~ APOE4 + PTAU + Hippocampus,
#                  data = Data_D1D2,
#                  Hess = TRUE)


Data_D1D2$Diagnosis <- as.factor(Data_D1D2$Diagnosis)
m1 <- multinom(Diagnosis ~ Hippocampus + MMSE + ABETA + APOE4,
                 data = Data_D1D2)
summary(m1)

# Identify outliers
residuals <- residuals(m1, type = "deviance")
print(residuals)

# Leverage
hat_values <- hatvalues(lm(model.matrix(m1) ~ Data_D1D2$Diagnosis))

# Cook's Distance
cooks_distance <- cooks.distance(lm(model.matrix(m1) ~ Data_D1D2$Diagnosis))
print(cooks_distance)

# Calculate average leverage
n <- nrow(Data_D1D2)
p <- length(coef(m1))  # Number of predictors (including intercept)
average_leverage <- (p + 1) / n
high_leverage_threshold <- 2 * average_leverage

# Identify high leverage points
high_leverage_points <- which(hat_values > high_leverage_threshold)
print(high_leverage_points)

# Determine if the regression line is significant
# Compare with a null model (only intercept)
null <- multinom(Diagnosis ~ 1, data = Data_D1D2)
lr_test <- anova(null, m1, test = "Chisq")
print(lr_test)

# Calculate McFadden's pseudo R-squared
null_logLik <- logLik(null)
full_logLik <- logLik(m1)
mcfadden_r2 <- 1 - as.numeric(full_logLik / null_logLik)
print(mcfadden_r2)

# Perform Statistics
car::Anova(m1, type = 3)


# 
# null <- MASS::polr(Diagnosis ~ 1, data = Data_D1D2, Hess = TRUE)
# lr_test <- anova(null, m1, test = "Chisq")
# print(lr_test)



# Get model predictions
# predicted <- predict(m1, type = "class")

# Create a confusion matrix
#confusionMatrix(predicted, Data_D1D2$Diagnosis)

# Pseudo R-squared
# mcfadden_r2 <- 1 - as.numeric(logLik(m1) / logLik(null))
# print(mcfadden_r2)
# 
# library(brant)
# brant(m1)


#library(lme4)
#model <- lmer(DXCHANGE ~ EXAMDATE + AGE + PTGENDER + (1|RID), data = Data_D1D2)

# The main measures to be predicted: DX, ADAS13, Ventricles
# Cognitive tests: CDRSB, ADAS11, MMSE, RAVLT_immediate
# MRI measures: Hippocampus, WholeBrain, Entorhinal, MidTemp
# PET measures: FDG, AV45
# CSF measures: ABETA_UPENNBIOMK9_04_19_17  (amyloid-beta level in CSF), TAU_UPENNBIOMK9_04_19_17 (tau level), PTAU_UPENNBIOMK9_04_19_17 (phosphorylated tau level)
# Risk factors: APOE4, AGE

# Main cognitive tests (excluding subtypes): - neuropsychological tests administered by a clinical expert 1. CDR Sum of Boxes 2. ADAS11 3. ADAS13 4. MMSE 5. RAVLT 6. Moca 7. Ecog
# MRI ROIs (Freesurfer) - measures of brain structural integrity 1. volumes 2. cortical thicknesses 3. surface areas
# FDG PET ROI averages - measure cell metabolism, where cells affected by AD show reduced metabolism
# AV45 PET ROI averages - measures amyloid-beta load in the brain, where amyloid-beta is a protein that mis-folds (i.e. its 3D structure is not properly constructed), which then leads to AD
# AV1451 PET ROI averages - measures tau load in the brain, where tau is another protein which, when abnormal, damages neurons and thus leads to AD
# DTI ROI measures - measures microstructural parameters related to cells and axons (cell radial diffusivity, axonal diffusivity, etc ... ) 1. Mean diffusivity 2. Axial diffusivity 3. Radial diffusivity
# CSF biomarkers - amyloid and tau levels in the cerebrospinal fluid (CSF), as opposed to the cerebral cortex
# Others: 1. APOE status - a gene that is a risk factor for developing AD 2. Demographic information: age, gender, education, etc ... 3. Diagnosis: either cognitively cormal (CN), mild cognitive impairment (MCI) or Alzheimer's disease (AD).
#   
```
```{r}
# GEE MODEL, LONGITUDINA/CATEGORICAL

library(tidyverse)
library(haven)
library(dplyr)
library(fastDummies)
library(nnet)
library(caret)
library(classpackage)
install.packages("glmmTMB")
library(glmmTMB)

Data_D1D2 <- read_csv("~/Capstone/TADPOLE_D1_D2_2.csv")

# Keep only baseline data that includes ABETA, TAU, and PTAU measures
Data_D1D2 <- Data_D1D2 %>% 
  filter(ABETA_UPENNBIOMK9_04_19_17 > 0,
         TAU_UPENNBIOMK9_04_19_17 > 0,
         PTAU_UPENNBIOMK9_04_19_17 > 0) %>%
   select(RID, VISCODE, PTMARRY, EXAMDATE, DX_bl, DX, DXCHANGE, AGE, PTGENDER, PTETHCAT, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, FDG, AV45, ABETA_UPENNBIOMK9_04_19_17, TAU_UPENNBIOMK9_04_19_17, PTAU_UPENNBIOMK9_04_19_17, Hippocampus, WholeBrain, Entorhinal, MidTemp) %>%
na.omit()

# Create a dataframe
Data_D1D2 <- as.data.frame(Data_D1D2)

# Rename columns
Data_D1D2 <- Data_D1D2 %>% rename(
  ABETA = ABETA_UPENNBIOMK9_04_19_17,
  TAU = TAU_UPENNBIOMK9_04_19_17,
  PTAU = PTAU_UPENNBIOMK9_04_19_17)

# Perform data cleanup and scale the parameters
Data_D1D2 <- Data_D1D2 %>%
  mutate(
    PTAU = as.numeric(PTAU))

# Handle missing data for other measures
Data_D1D2 <- Data_D1D2
for(i in 1:ncol(Data_D1D2)) {
  if(is.numeric(Data_D1D2[[i]])) {
    Data_D1D2[[i]][is.na(Data_D1D2[[i]])] <- mean(Data_D1D2[[i]], na.rm = TRUE)
  }
}

Data_D1D2$DX_bl <- as.factor(Data_D1D2$DX_bl)

# Create an indicator variable for educatiom status
Data_D1D2 <- Data_D1D2 %>%
  mutate(Diagnosis = case_when(DX_bl == 'AD' ~"5-AD",          
                                  DX_bl == 'LMCI' ~ "4-LMCI",  
                                  DX_bl == 'EMCI' ~ "3-EMCI",
                                  DX_bl == 'SMC' ~ "2-SMC",
                                  TRUE ~ "1-NC")) %>%           
dummy_cols(select_columns = c("Diagnosis"))  

Data_D1D2 <- Data_D1D2 %>%
  mutate(Gender = case_when(PTGENDER == 'Female' ~"Female",
                                  TRUE ~ "Male")) %>%
dummy_cols(select_columns = c("Gender"))



# Fit a mixed-effects multinomial model
mixed_model <- glmmTMB(Diagnosis ~ treatment + time + (1 | subject_id), 
                        data = data, 
                        family = multinomial())

# Summary of the mixed model
summary(mixed_model)
```

```{r}

##EXAMPLES

# Load necessary libraries
library(lme4)       # For mixed-effects models
library(pROC)       # For ROC curve and AUC
library(tidyverse)
library(haven)
library(dplyr)
library(fastDummies)
#install.packages("caret")
library(caret)

Data_D1D2 <- read_csv("~/Capstone/TADPOLE_D1_D2_2.csv")
Data_D1D2 <- Data_D1D2  %>%
  select(RID, VISCODE, PTMARRY, EXAMDATE, DX_bl, DX, DXCHANGE, AGE, PTGENDER, PTETHCAT, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, FDG, AV45, ABETA_UPENNBIOMK9_04_19_17, TAU_UPENNBIOMK9_04_19_17, PTAU_UPENNBIOMK9_04_19_17, Hippocampus, WholeBrain, Entorhinal, MidTemp) 

# Create an indicator variable for educatiom status
Data_D1D2 <- Data_D1D2 %>%
  mutate(Diagnosis = case_when(DX_bl == 'AD' ~"5-AD",          
                                  DX_bl == 'LMCI' ~ "4-LMCI",  
                                  DX_bl == 'EMCI' ~ "3-EMCI",
                                  DX_bl == 'SMC' ~ "2-SMC",
                                  TRUE ~ "1-NC")) %>%           
dummy_cols(select_columns = c("Diagnosis"))  

Data_D1D2 <- Data_D1D2 %>%
  mutate(Gender = case_when(PTGENDER == 'Female' ~"Female",          
                                  TRUE ~ "Male")) %>%           
dummy_cols(select_columns = c("Gender"))  

#Handle missing data
Data_D1D2 <- Data_D1D2
for(i in 1:ncol(Data_D1D2_imputed)) {
  if(is.numeric(Data_D1D2_imputed[[i]])) {
    Data_D1D2_imputed[[i]][is.na(Data_D1D2_imputed[[i]])] <- mean(Data_D1D2_imputed[[i]], na.rm = TRUE)
  }
}
write.csv(Data_D1D2, "~/Capstone/Subset_D1D1.csv", row.names = TRUE)

Data_D1D2  %>%
  select(RID, VISCODE, PTMARRY, EXAMDATE, DX_bl, DXCHANGE, DX, AGE, PTGENDER, PTETHCAT, CDRSB, ADAS11, MMSE, RAVLT_immediate, APOE4, FDG, AV45, ABETA_UPENNBIOMK9_04_19_17, TAU_UPENNBIOMK9_04_19_17, PTAU_UPENNBIOMK9_04_19_17, Hippocampus, WholeBrain, Entorhinal, MidTemp) %>%
head(n=50)

# # Convert DX to a factor for multinomial classification
# Data_D1D2$DX_bl <- as.factor(Data_D1D2$DX_bl)
# 
# # Example data frame with subject ID, time points, and other variables
# set.seed(123)  # For reproducibility
# subject_ids <- unique(Data_D1D2$RID)
# 
# # Randomly select 70% of subjects for training
# train_subjects <- sample(subject_ids, size = 0.7 * length(subject_ids))

# Subset the data based on selected subjects
# train_data <- Data_D1D2[Data_D1D2$RID %in% train_subjects, ]
# test_data <- Data_D1D2[!Data_D1D2$RID %in% train_subjects, ]
# view(train_data)
# view(test_data)

library(nnet)
m1 <- multinom(DX_bl ~ AGE + ABETA_UPENNBIOMK9_04_19_17, TAU_UPENNBIOMK9_04_19_17, 
                 data = Data_D1D2)
summary(m1)




# Fit a generalized linear mixed-effects model (GLMM)
# Random effect: intercept for each subject (ID)
# Fixed effects: MMSE, APOE4, CSF_ABETA, CSF_TAU, CSF_PTAU

# model <- lmer(DX ~ MMSE +
#                (1 | RID),
#                data = train_data,
#                family = binomial(link = "logit"))
      #         control = glmerControl(optimizer = "bobyqa"))

# Display model summary
# summary(model)

# # Load or simulate your dataset
# # alzheimer_data <- read.csv("path/to/your/data.csv")
# 
# # Assuming alzheimer_data is already loaded
# 
# # View the structure of the dataset
# str(alzheimer_data)
# 
# # Check for missing values and handle them (imputation or removal)
# alzheimer_data <- na.omit(alzheimer_data)  # Simple removal for illustration
# 
# # Split data into training and testing sets
# set.seed(42)
# trainIndex <- createDataPartition(alzheimer_data$DX, p = 0.8, 
#                                   list = FALSE, 
#                                   times = 1)
# train_data <- alzheimer_data[trainIndex, ]
# test_data <- alzheimer_data[-trainIndex, ]



# # Predictions on test data
# test_data$pred_prob <- predict(model, test_data, type = "response")
# test_data$pred_DX <- ifelse(test_data$pred_prob > 0.5, "AD", "CN")
# 
# # Evaluate model performance
# # Confusion Matrix
# conf_matrix <- confusionMatrix(factor(test_data$pred_DX), factor(test_data$DX))
# print(conf_matrix)
# 
# # Calculate AUC
# roc_obj <- roc(test_data$DX, test_data$pred_prob)
# auc_value <- auc(roc_obj)
# cat("AUC:", auc_value, "\n")
# 
# # Plot ROC curve
# plot(roc_obj, col = "blue", main = "ROC Curve for Alzheimer's Disease Prediction")
# abline(a = 0, b = 1, col = "red", lty = 2)

```








